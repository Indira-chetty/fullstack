🔍 Real-Time Assistive System for Visually Impaired People
This project is an AI-powered assistive system designed to help visually impaired individuals interact with their surroundings more independently. It uses advanced computer vision and speech technologies to recognize objects and read text from the environment in real time, then converts the information into audio feedback.

💡 Key Features:
🔎 Object Detection using YOLOv5 to recognize everyday items in the user's environment.

📄 Text Recognition with PaddleOCR to read printed or handwritten text from captured images.

🔊 Audio Feedback via Google Text-to-Speech (gTTS) for real-time narration of detected content.

📸 Supports Multiple Modes: live camera feed, image capture, and image upload.

🧠 Technologies Used:
YOLOv5 (Object Detection)

PaddleOCR (Optical Character Recognition)

gTTS (Text to Speech)

OpenCV, Flask, Python

🚀 Goal:
To empower visually impaired individuals by providing a low-cost, real-time, and user-friendly tool that bridges the gap between visual information and accessible audio content.
